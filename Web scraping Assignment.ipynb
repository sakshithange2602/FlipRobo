{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1. Write a python program to display all the header tags from\\n‘en.wikipedia.org/wiki/Main_Page’.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Q1. Write a python program to display all the header tags from\n",
    "‘en.wikipedia.org/wiki/Main_Page’.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>,\n",
       " <h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>,\n",
       " <h2>Navigation menu</h2>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
       " <span>Personal tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
       " <span>Namespaces</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
       " <span>Variants</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
       " <span>Views</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
       " <span>More</span>\n",
       " </h3>,\n",
       " <h3>\n",
       " <label for=\"searchInput\">Search</label>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
       " <span>Navigation</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
       " <span>Contribute</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
       " <span>Tools</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
       " <span>Print/export</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
       " <span>In other projects</span>\n",
       " </h3>,\n",
       " <h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
       " <span>Languages</span>\n",
       " </h3>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://en.wikipedia.org/wiki/Main_Page\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "headertags=soup.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "headertags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name,\\nIMDB rating, Year of release) and save it in form of a CSV file. '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name,\n",
    "IMDB rating, Year of release) and save it in form of a CSV file. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieName</th>\n",
       "      <th>ReleaseYear</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      The Shawshank Redemption(1994)</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      The Godfather(1972)</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      The Godfather: Part II(1974)</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      The Dark Knight(2008)</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      12 Angry Men(1957)</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      Citizen Kane(1941)</td>\n",
       "      <td>1941</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      Dangal(2016)</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Idi i smotri(1985)</td>\n",
       "      <td>1985</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      The Kid(1921)</td>\n",
       "      <td>1921</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Singin' in the Rain(1952)</td>\n",
       "      <td>1952</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       MovieName ReleaseYear Ratings\n",
       "0         1.      The Shawshank Redemption(1994)        1994     9.2\n",
       "1                    2.      The Godfather(1972)        1972     9.1\n",
       "2           3.      The Godfather: Part II(1974)        1974     9.0\n",
       "3                  4.      The Dark Knight(2008)        2008     9.0\n",
       "4                     5.      12 Angry Men(1957)        1957     8.9\n",
       "..                                           ...         ...     ...\n",
       "95                   96.      Citizen Kane(1941)        1941     8.3\n",
       "96                         97.      Dangal(2016)        2016     8.3\n",
       "97                   98.      Idi i smotri(1985)        1985     8.2\n",
       "98                        99.      The Kid(1921)        1921     8.2\n",
       "99           100.      Singin' in the Rain(1952)        1952     8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Finding all bomovieok names\n",
    "MovieName=soup.find_all('td',class_=\"titleColumn\")\n",
    "movie_names=[]\n",
    "for i in MovieName:\n",
    "    movie_names.append(i.text.replace('\\n',''))\n",
    "\n",
    "\n",
    "#Finding all mpvie release year\n",
    "ReleaseYear=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "Release_Years=[]\n",
    "for i in ReleaseYear:\n",
    "    Release_Years.append(i.text.replace('\\n','').replace('(','').replace(')',''))\n",
    "    \n",
    "    \n",
    "#Finding all movie ratings\n",
    "rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "Ratings=[]\n",
    "for i in rating:\n",
    "    Ratings.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "#Putting all data in table\n",
    "import pandas as pd\n",
    "movies=pd.DataFrame({})\n",
    "for i in range(0,5):\n",
    "    movies['MovieName']=movie_names\n",
    "    movies['ReleaseYear']=Release_Years\n",
    "    movies['Ratings']=Ratings\n",
    "\n",
    "\n",
    "movies.to_csv('IMDBTop100Movies.csv')\n",
    "movies.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q3.Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieName</th>\n",
       "      <th>ReleaseYear</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.      Pather Panchali(1955)</td>\n",
       "      <td>1955</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.      Gol Maal(1979)</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.      Nayakan(1987)</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.      Anbe Sivam(2003)</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.      Apur Sansar(1959)</td>\n",
       "      <td>1959</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.      The Legend of Bhagat Singh(2002)</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.      Barfi!(2012)</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.      Pink(2016)</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.      Bommarillu(2006)</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.      Bombay(1995)</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          MovieName ReleaseYear Ratings\n",
       "0                     1.      Pather Panchali(1955)        1955     8.5\n",
       "1                            2.      Gol Maal(1979)        1979     8.5\n",
       "2                             3.      Nayakan(1987)        1987     8.5\n",
       "3                          4.      Anbe Sivam(2003)        2003     8.5\n",
       "4                         5.      Apur Sansar(1959)        1959     8.5\n",
       "..                                              ...         ...     ...\n",
       "95        96.      The Legend of Bhagat Singh(2002)        2002     8.0\n",
       "96                            97.      Barfi!(2012)        2012     8.0\n",
       "97                              98.      Pink(2016)        2016     8.0\n",
       "98                        99.      Bommarillu(2006)        2006     8.0\n",
       "99                           100.      Bombay(1995)        1995     8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=2e9dfa9b-3e4d-4d39-acd2-8af11f252a59&pf_rd_r=7YVJAT975NWQNRN6FHS1&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Finding all bomovieok names\n",
    "MovieName=soup.find_all('td',class_=\"titleColumn\")\n",
    "movie_names=[]\n",
    "for i in MovieName:\n",
    "    movie_names.append(i.text.replace('\\n',''))\n",
    "\n",
    "\n",
    "#Finding all mpvie release year\n",
    "ReleaseYear=soup.find_all('span',class_=\"secondaryInfo\")\n",
    "Release_Years=[]\n",
    "for i in ReleaseYear:\n",
    "    Release_Years.append(i.text.replace('\\n','').replace('(','').replace(')',''))\n",
    "    \n",
    "    \n",
    "#Finding all movie ratings\n",
    "rating=soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "Ratings=[]\n",
    "for i in rating:\n",
    "    Ratings.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "    \n",
    "#Putting all data in table\n",
    "import pandas as pd\n",
    "movies=pd.DataFrame({})\n",
    "for i in range(0,5):\n",
    "    movies['MovieName']=movie_names\n",
    "    movies['ReleaseYear']=Release_Years\n",
    "    movies['Ratings']=Ratings\n",
    "\n",
    "\n",
    "movies.to_csv('IMDBTop100IndianMovies.csv')\n",
    "movies.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q4.Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookName</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Last Thing He Told Me</td>\n",
       "      <td>Laura Dave</td>\n",
       "      <td>Fiction / Family Drama</td>\n",
       "      <td>Laura Dave has given us what we crave right no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Secret History of Home Economics</td>\n",
       "      <td>Danielle Dreilinger</td>\n",
       "      <td>Nonfiction / History / Women's History</td>\n",
       "      <td>Whatever stereotypes we associate with home ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Little and Often</td>\n",
       "      <td>Trent Preszler</td>\n",
       "      <td>Nonfiction / Memoir / Family &amp; Relationships</td>\n",
       "      <td>This lucid, lyrical memoir recalls father-son ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Wreckage of My Presence</td>\n",
       "      <td>Casey Wilson</td>\n",
       "      <td>Nonfiction / Essays / Humor</td>\n",
       "      <td>The Wreckage of My Presence is funny and bold,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>★ Secrets of Happiness</td>\n",
       "      <td>Joan Silber</td>\n",
       "      <td>Fiction / Family Drama</td>\n",
       "      <td>Rarely is a novel of moral ideas so buoyant in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               BookName               Author  \\\n",
       "0             The Last Thing He Told Me           Laura Dave   \n",
       "1  The Secret History of Home Economics  Danielle Dreilinger   \n",
       "2                      Little and Often       Trent Preszler   \n",
       "3           The Wreckage of My Presence         Casey Wilson   \n",
       "4                ★ Secrets of Happiness          Joan Silber   \n",
       "\n",
       "                                          Genre  \\\n",
       "0                        Fiction / Family Drama   \n",
       "1        Nonfiction / History / Women's History   \n",
       "2  Nonfiction / Memoir / Family & Relationships   \n",
       "3                   Nonfiction / Essays / Humor   \n",
       "4                        Fiction / Family Drama   \n",
       "\n",
       "                                              Review  \n",
       "0  Laura Dave has given us what we crave right no...  \n",
       "1  Whatever stereotypes we associate with home ec...  \n",
       "2  This lucid, lyrical memoir recalls father-son ...  \n",
       "3  The Wreckage of My Presence is funny and bold,...  \n",
       "4  Rarely is a novel of moral ideas so buoyant in...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://bookpage.com/reviews\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "#Finding all book names\n",
    "BookName=soup.find_all('h4',class_=\"italic\")\n",
    "book_names=[]\n",
    "for i in BookName:\n",
    "    book_names.append(i.text.replace('\\n',''))\n",
    "\n",
    "\n",
    "#Finding all book authors\n",
    "AuthorName=soup.find_all('p',class_=\"sans bold\")\n",
    "author_names=[]\n",
    "for i in AuthorName:\n",
    "    author_names.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "#Finding all book genres\n",
    "genre=soup.find_all('p',class_=\"genre-links hidden-phone\")\n",
    "genres=[]\n",
    "for i in genre:\n",
    "    genres.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "#Finding all book reviews\n",
    "BookReview=soup.find_all('p',class_=\"excerpt\")\n",
    "Reviews=[]\n",
    "for i in BookReview:\n",
    "    Reviews.append(i.text.replace('\\n',''))\n",
    "    \n",
    "    \n",
    "#Putting all data in table\n",
    "import pandas as pd\n",
    "books=pd.DataFrame({})\n",
    "for i in range(0,5):\n",
    "    books['BookName']=book_names\n",
    "    books['Author']=author_names\n",
    "    books['Genre']=genres\n",
    "    books['Review']=Reviews\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q5.Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\\ni) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q5.Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Top 10 Teams---------------\n",
      "Teams [['New Zealand', 'Australia', 'India', 'England', 'South Africa', 'Pakistan', 'Bangladesh', 'West Indies', 'Sri Lanka', 'Afghanistan']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Matches ['17', ['25', '29', '27', '20', '24', '24', '27', '21', '17']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Points ['2,054', ['2,945', '3,344', '3,100', '2,137', '2,323', '2,157', '2,222', '1,652', '1,054']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Ratings ['                            121                            ', ['118', '115', '115', '107', '97', '90', '82', '79', '62']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#extract all teams\n",
    "teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "Team1=[]\n",
    "Team2=[]\n",
    "for i in teams:\n",
    "    Team1.append(i.text.replace('\\n',''))\n",
    "Team2.append(Team1[0:10])\n",
    "\n",
    "\n",
    "#extract all matches\n",
    "Match1=[]\n",
    "topteammatch=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "Match1.append(topteammatch.text)\n",
    "Match2=[]\n",
    "matches=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in matches:\n",
    "    Match2.append(i.text.replace('\\n',''))\n",
    "Match1.append(Match2[0:18:2])\n",
    "\n",
    "#extract all points\n",
    "Points1=[]\n",
    "topteampoints=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "Points1.append(topteampoints.text)\n",
    "Points2=[]\n",
    "points=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in points:\n",
    "    Points2.append(i.text.replace('\\n',''))\n",
    "Points1.append(Points2[1:19:2])\n",
    "\n",
    "\n",
    "#extract all ratings\n",
    "Ratings1=[]\n",
    "topteamrating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Ratings1.append(topteamrating.text.replace('\\n',''))\n",
    "ratings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "Rating=[]\n",
    "for i in ratings:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "Ratings1.append(Rating[0:9])\n",
    "\n",
    "\n",
    "\n",
    "print('------------Top 10 Teams---------------')\n",
    "print('Teams',Team2)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Matches',Match1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Points',Points1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Ratings',Ratings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ii) Top 10 ODI Batsmen in men along with the records of their team and rating.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ii) Top 10 ODI Batsmen in men along with the records of their team and rating.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Top 10 Batsmen---------------\n",
      "Players Name ['Babar Azam', ['Virat Kohli', 'Rohit Sharma', 'Ross Taylor', 'Aaron Finch', 'Jonny Bairstow', 'Fakhar Zaman', 'Francois du Plessis', 'David Warner', 'Shai Hope']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Nationality ['PAK865', ['IND', 'IND', 'NZ', 'AUS', 'ENG', 'PAK', 'SA', 'AUS', 'WI']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Ratings ['865', ['857', '825', '801', '791', '785', '778', '778', '773', '773']]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#extract all batsmen\n",
    "Player1=[]\n",
    "Playername1=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "Player1.append(Playername1.text)\n",
    "Player2=[]\n",
    "players=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "for i in players:\n",
    "    Player2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Player1.append(Player2[0:9])\n",
    "\n",
    "#extract all batsmen nationality\n",
    "Nation1=[]\n",
    "nationname1=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n',''))\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')\n",
    "\n",
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])\n",
    "\n",
    "#extract all batsmen ratings\n",
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])\n",
    "\n",
    "\n",
    "#Printing data\n",
    "print('------------Top 10 Batsmen---------------')\n",
    "print('Players Name',Player1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\\ni) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Top 10 Teams---------------\n",
      "Teams [['Australia', 'South Africa', 'England', 'India', 'New Zealand', 'West Indies', 'Pakistan', 'Bangladesh', 'Sri Lanka', 'Ireland']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Matches ['18', ['24', '17', '20', '21', '12', '15', '5', '11', '2']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Points ['2,955', ['2,828', '1,993', '2,226', '1,947', '1,025', '1,101', '306', '519', '25']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Ratings ['                            164                            ', ['118', '117', '111', '93', '85', '73', '61', '47', '13']]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#extract all teams\n",
    "teams=soup.find_all('span',class_='u-hide-phablet')\n",
    "Team1=[]\n",
    "Team2=[]\n",
    "for i in teams:\n",
    "    Team1.append(i.text.replace('\\n',''))\n",
    "Team2.append(Team1[0:10])\n",
    "\n",
    "\n",
    "#extract all matches\n",
    "Match1=[]\n",
    "topteammatch=soup.find('td',class_=\"rankings-block__banner--matches\")\n",
    "Match1.append(topteammatch.text)\n",
    "Match2=[]\n",
    "matches=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in matches:\n",
    "    Match2.append(i.text.replace('\\n',''))\n",
    "Match1.append(Match2[0:18:2])\n",
    "\n",
    "#extract all points\n",
    "Points1=[]\n",
    "topteampoints=soup.find('td',class_=\"rankings-block__banner--points\")\n",
    "Points1.append(topteampoints.text)\n",
    "Points2=[]\n",
    "points=soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "\n",
    "for i in points:\n",
    "    Points2.append(i.text.replace('\\n',''))\n",
    "Points1.append(Points2[1:19:2])\n",
    "\n",
    "\n",
    "#extract all ratings\n",
    "Ratings1=[]\n",
    "topteamrating=soup.find('td',class_=\"rankings-block__banner--rating u-text-right\")\n",
    "Ratings1.append(topteamrating.text.replace('\\n',''))\n",
    "ratings=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "Rating=[]\n",
    "for i in ratings:\n",
    "    Rating.append(i.text.replace('\\n',''))\n",
    "Ratings1.append(Rating[0:9])\n",
    "\n",
    "\n",
    "\n",
    "print('------------Top 10 Teams---------------')\n",
    "print('Teams',Team2)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Matches',Match1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Points',Points1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Ratings',Ratings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ii) Top 10 women’s ODI players along with the records of their team and rating.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ii) Top 10 women’s ODI players along with the records of their team and rating.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Top 10 Batsmen---------------\n",
      "Players Name ['Tammy Beaumont', ['Lizelle Lee', 'Alyssa Healy', 'Stafanie Taylor', 'Meg Lanning', 'Amy Satterthwaite', 'Smriti Mandhana', 'Mithali Raj', 'Natalie Sciver', 'Laura Wolvaardt']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Nationality ['ENG765', ['SA', 'AUS', 'WI', 'AUS', 'NZ', 'IND', 'IND', 'ENG', 'SA']]\n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Ratings ['765', ['758', '756', '746', '723', '715', '710', '709', '685', '683']]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#extract all batsmen\n",
    "Player1=[]\n",
    "Playername1=soup.find('div',class_=\"rankings-block__banner--name\")\n",
    "Player1.append(Playername1.text)\n",
    "Player2=[]\n",
    "players=soup.find_all('td',class_='table-body__cell name')\n",
    "\n",
    "for i in players:\n",
    "    Player2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Player1.append(Player2[0:9])\n",
    "\n",
    "#extract all batsmen nationality\n",
    "Nation1=[]\n",
    "nationname1=soup.find('div',class_=\"rankings-block__banner--nationality\")\n",
    "Nation1.append(nationname1.text.replace('\\n',''))\n",
    "Nation2=[]\n",
    "nationname2=soup.find_all('span',class_='table-body__logo-text')\n",
    "\n",
    "for i in nationname2:\n",
    "    Nation2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Nation1.append(Nation2[0:9])\n",
    "\n",
    "#extract all batsmen ratings\n",
    "Rating1=[]\n",
    "ratings1=soup.find('div',class_=\"rankings-block__banner--rating\")\n",
    "Rating1.append(ratings1.text)\n",
    "Rating2=[]\n",
    "ratings2=soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "\n",
    "for i in ratings2:\n",
    "    Rating2.append(i.text.replace('\\n',''))\n",
    "    \n",
    "Rating1.append(Rating2[0:9])\n",
    "\n",
    "\n",
    "#Printing data\n",
    "print('------------Top 10 Batsmen---------------')\n",
    "print('Players Name',Player1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Nationality',Nation1)\n",
    "print('\\n')\n",
    "print('---------------------------------------')\n",
    "print('Ratings',Rating1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q7.Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q7.Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page=requests.get(\"https://www.amazon.in/s?k=mobile+phones+under+20000+rupees&crid=3GOT1MYB6JZ4H&sprefix=mobile+phones+under+20%2Caps%2C292&ref=nb_sb_ss_ts-doa-p_2_22\")\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "Product=soup.find_all('span',class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "product_names=[]\n",
    "for i in Product:\n",
    "    product_names.append(i.text.replace('\\n',''))\n",
    "    \n",
    "\n",
    "Price=soup.find_all('span',class_=\"a-price-whole\")\n",
    "product_prices=[]\n",
    "for i in Price:\n",
    "    product_prices.append(i.text.replace('\\n',''))\n",
    "\n",
    "    \n",
    "Image_URL=[]\n",
    "for item in soup.find_all('img',class_=\"s-image\"):\n",
    "    Image_URL.append(item['src'])\n",
    "    \n",
    "    \n",
    "rating=soup.find_all('span',class_=\"a-icon-alt\")\n",
    "ratings=[]\n",
    "for i in rating:\n",
    "    ratings.append(i.text.replace('\\n',''))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q8.Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Q8.Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Today', 'Tonight', 'Friday', 'FridayNight', 'Saturday', 'SaturdayNight', 'Sunday', 'SundayNight', 'Monday']\n",
      "['BecomingSunny', 'Mostly Clear', 'Sunny', 'Clear', 'Sunny', 'Mostly Clear', 'Sunny', 'Clear', 'Sunny']\n",
      "['High: 63 °F', 'Low: 50 °F', 'High: 66 °F', 'Low: 50 °F', 'High: 72 °F', 'Low: 53 °F', 'High: 70 °F', 'Low: 52 °F', 'High: 72 °F']\n",
      "['Today: Cloudy through mid morning, then gradual clearing, with a high near 63. West wind 8 to 17 mph, with gusts as high as 22 mph. ', 'Tonight: Mostly clear, with a low around 50. West wind 11 to 16 mph, with gusts as high as 21 mph. ', 'Friday: Sunny, with a high near 66. Light and variable wind becoming west 10 to 15 mph in the afternoon. Winds could gust as high as 18 mph. ', 'Friday Night: Clear, with a low around 50. West wind 5 to 14 mph, with gusts as high as 18 mph. ', 'Saturday: Sunny, with a high near 72. North northwest wind 9 to 11 mph, with gusts as high as 26 mph. ', 'Saturday Night: Mostly clear, with a low around 53.', 'Sunday: Sunny, with a high near 70.', 'Sunday Night: Clear, with a low around 52.', 'Monday: Sunny, with a high near 72.']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "\n",
    "\n",
    "periods = [pr.get_text() for pr in seven_day.select(\".tombstone-container .period-name\")]\n",
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "print(periods)\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
